{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing numeric table\n",
    "import pandas as pd\n",
    "training_df = pd.read_csv('/home/data/MSA8010/msa8010f16t03/data/pr_training_7l_p5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dropping the first column from categorical_with_id_df table\n",
    "training_df2=training_df.drop(training_df.columns[[0]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "710248"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training_df2.head(5)\n",
    "len(training_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_df = pd.read_csv('/home/data/MSA8010/msa8010f16t03/data/pr_test_5l_p5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dropping the first column from categorical_with_id_df table\n",
    "validation_df2=validation_df.drop(validation_df.columns[[0]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "473499"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training_df2.head(5)\n",
    "len(validation_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.4/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/lib64/python3.4/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "\n",
    "train = training_df2\n",
    "target = 'Response'\n",
    "IDcol = 'Id'\n",
    "validation=validation_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4127"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dvalidation_predictions=pd.DataFrame()\n",
    "\n",
    "def modelfit(alg, dtrain, dvalidation,predictors,useTrainCV=True, cv_folds=5, early_stopping_rounds=10):\n",
    "    \n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(dtrain[predictors].values, label=dtrain[target].values)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds,callbacks=[xgb.callback.print_evaluation(show_stdv=True)])\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "        print(\"Number of boosted trees is n_estimaors which is %d\" %(cvresult.shape[0]))\n",
    "        print(cvresult)\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(dtrain[predictors], dtrain['Response'],eval_metric='auc')\n",
    "        \n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "    \n",
    "    #Predict validation set:\n",
    "    dvalidation_predictions = alg.predict(dvalidation[predictors])\n",
    "   \n",
    "    dvalidation_predprob = alg.predict_proba(dvalidation[predictors])[:,1]\n",
    "    \n",
    "    \n",
    "        \n",
    "#Print model report:\n",
    "    print(\"\\nTotal Number of 1's predicted in the training dataset is %d\" %(sum(dtrain_predictions)))  \n",
    "    print(\"\\nActual Number of 1's in the training dataset is %d\" %(sum(dtrain.Response)) )\n",
    "    print(\"\\nTotal number of 0's predicted in the training dataset is %d\" %(len(dtrain_predictions)-sum(dtrain_predictions)))\n",
    "    print(\"\\nTotal number of 0's in the training dataset is %d\" %(len(dtrain)-sum(dtrain.Response)))\n",
    "    print (\"\\nModel Report\")\n",
    "    print (\"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['Response'].values, dtrain_predictions))\n",
    "    print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['Response'], dtrain_predprob))\n",
    "                    \n",
    "    #feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    #print(feat_imp)\n",
    "    #feat_imp.plot(kind='bar', figsize=(15,10),title='Feature Importances')\n",
    "    #plt.ylabel('Feature Importance Score')\n",
    "\n",
    "#Print validation model report:\n",
    "    print(\"\\nTotal Number of 1's predicted in the validation dataset is %d\" %(sum(dvalidation_predictions)))  \n",
    "    print(\"\\nActual Number of 1's in the validation dataset is %d\" %(sum(dvalidation.Response)) )\n",
    "    print(\"\\nTotal number of 0's predicted in the validation dataset is %d\" %(len(dvalidation_predictions)-sum(dvalidation_predictions)))\n",
    "    print(\"\\nTotal number of 0's in the validation dataset is %d\" %(len(dvalidation)-sum(dvalidation.Response)))\n",
    "    print(\"\\nModel Report on validation set\")\n",
    "    print(\"Accuracy : %.4g\" % metrics.accuracy_score(dvalidation['Response'].values, dvalidation_predictions))\n",
    "    print(\"AUC Score (Validation): %f\" % metrics.roc_auc_score(dvalidation['Response'], dvalidation_predprob))\n",
    "    \n",
    "    return dvalidation_predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.588248+0.0105358\ttest-auc:0.587805+0.0111015\n",
      "[1]\ttrain-auc:0.601953+0.00546296\ttest-auc:0.597316+0.0103689\n",
      "[2]\ttrain-auc:0.609822+0.00565102\ttest-auc:0.604246+0.0120949\n",
      "[3]\ttrain-auc:0.616807+0.00378558\ttest-auc:0.609905+0.0119735\n",
      "[4]\ttrain-auc:0.624286+0.00281218\ttest-auc:0.618762+0.00798054\n",
      "[5]\ttrain-auc:0.655652+0.00905892\ttest-auc:0.649728+0.0142096\n",
      "[6]\ttrain-auc:0.657731+0.00468231\ttest-auc:0.65054+0.00461305\n",
      "[7]\ttrain-auc:0.663542+0.00513045\ttest-auc:0.65581+0.00652974\n",
      "[8]\ttrain-auc:0.666454+0.00644184\ttest-auc:0.65557+0.00732638\n",
      "[9]\ttrain-auc:0.668379+0.00652626\ttest-auc:0.657701+0.00804422\n",
      "[10]\ttrain-auc:0.67132+0.00778029\ttest-auc:0.659485+0.0085315\n",
      "[11]\ttrain-auc:0.675439+0.00557135\ttest-auc:0.662743+0.00615078\n",
      "[12]\ttrain-auc:0.678408+0.00494547\ttest-auc:0.662272+0.00623656\n",
      "[13]\ttrain-auc:0.682939+0.00497887\ttest-auc:0.662294+0.00678103\n",
      "[14]\ttrain-auc:0.685239+0.00574824\ttest-auc:0.661681+0.00584852\n",
      "[15]\ttrain-auc:0.68822+0.00556545\ttest-auc:0.662098+0.00451769\n",
      "[16]\ttrain-auc:0.68868+0.00363886\ttest-auc:0.661539+0.00399645\n",
      "[17]\ttrain-auc:0.691637+0.00482698\ttest-auc:0.663005+0.00397672\n",
      "[18]\ttrain-auc:0.694626+0.00479281\ttest-auc:0.664359+0.00441938\n",
      "[19]\ttrain-auc:0.696807+0.00467282\ttest-auc:0.664646+0.00359048\n",
      "Number of boosted trees is n_estimaors which is 20\n",
      "    test-auc-mean  test-auc-std  train-auc-mean  train-auc-std\n",
      "0        0.587805      0.011102        0.588248       0.010536\n",
      "1        0.597316      0.010369        0.601953       0.005463\n",
      "2        0.604246      0.012095        0.609822       0.005651\n",
      "3        0.609905      0.011973        0.616807       0.003786\n",
      "4        0.618762      0.007981        0.624286       0.002812\n",
      "5        0.649728      0.014210        0.655652       0.009059\n",
      "6        0.650540      0.004613        0.657731       0.004682\n",
      "7        0.655810      0.006530        0.663542       0.005130\n",
      "8        0.655570      0.007326        0.666454       0.006442\n",
      "9        0.657701      0.008044        0.668379       0.006526\n",
      "10       0.659485      0.008531        0.671320       0.007780\n",
      "11       0.662743      0.006151        0.675439       0.005571\n",
      "12       0.662272      0.006237        0.678408       0.004945\n",
      "13       0.662294      0.006781        0.682939       0.004979\n",
      "14       0.661681      0.005849        0.685239       0.005748\n",
      "15       0.662098      0.004518        0.688220       0.005565\n",
      "16       0.661539      0.003996        0.688680       0.003639\n",
      "17       0.663005      0.003977        0.691637       0.004827\n",
      "18       0.664359      0.004419        0.694626       0.004793\n",
      "19       0.664646      0.003590        0.696807       0.004673\n",
      "\n",
      "Total Number of 1's predicted in the training dataset is 3\n",
      "\n",
      "Actual Number of 1's in the training dataset is 4127\n",
      "\n",
      "Total number of 0's predicted in the training dataset is 710245\n",
      "\n",
      "Total number of 0's in the training dataset is 706121\n",
      "\n",
      "Model Report\n",
      "Accuracy : 0.9942\n",
      "AUC Score (Train): 0.693474\n",
      "\n",
      "Total Number of 1's predicted in the validation dataset is 1\n",
      "\n",
      "Actual Number of 1's in the validation dataset is 2752\n",
      "\n",
      "Total number of 0's predicted in the validation dataset is 473498\n",
      "\n",
      "Total number of 0's in the validation dataset is 470747\n",
      "\n",
      "Model Report on validation set\n",
      "Accuracy : 0.9942\n",
      "AUC Score (Validation): 0.675122\n"
     ]
    }
   ],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "predictors = [x for x in train.columns if x not in [target, IDcol]]\n",
    "xgb1 =XGBClassifier(learning_rate =0.9,\n",
    " n_estimators=20,\n",
    " max_depth=2,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "f=modelfit(xgb1, train, validation,predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#creating a confusion matrix from xgboost model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "predict=f\n",
    "actual=validation.Response.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[470746,      1],\n",
       "       [  2752,      0]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#confusion matrix\n",
    "confusion_matrix(actual,predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
